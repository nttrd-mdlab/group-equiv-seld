"""
Parameters for experimental conditions
"""


def get_params():
    cnn_half_time_len = 16  # Half length (time direction) of the Time-Frequency convolution layer
    params = dict(
        model=['Conventional', 'Proposed'][1],
        dataset_type=['normal', 'singlesource'][0],  # 'single source' exclude the sound segments multiple sound events occur simultaneously.
        dataset_dir='./tausse_extracted/',  # Path to the training/validation/evaluation dataset generated by `feature_extraction.py`.
        batch_size=12,
        seq_len=128,  # Frame length of the signals input to the DNNs.
        train_splits=[1, 3, 4],  # training / validation / evaluation splits (0, 1, 2, 3, 4)
        validation_splits=[2],
        evaluation_splits=[0],
        doa_loss_weight=1.0,
        max_epoch=300,
        wait_limit_epoch=1000,  # Training phase is terminated when validation score does not improve while last `wait_limit_epoch` epochs.
        learning_rate=0.001,
        learning_rate_scheduling=False,  # Enable learning rate scheduling or not (NOT used in the reported experiments)
        weight_decay=1e-5,
        bce_weight=1.0,
        nb_freq_bin_use=1024,  # Number of frequency bins actually used for training/estimation (max: 1024)
        label_trim=0,

        # To introduce time translation invariance (Section III.D), divide the input signal by the phase component of the l=0 channel,
        # `feature_phase_different_bin`-th preceding frame (In the paper, this value is fixed to `0`.)
        # If this value is set to `None`, such operation is omitted (= time translation invariance is ignored).
        feature_phase_different_bin=0,

        # Rotating the Ambisonic signals before they are fed into the DNNs.
        # `virtual_rot`: Virtually rotate the signals so that the directions of sound events are statistically biased to specific directions.
        # `azi_random`: Virtually rotate the signals by completely random azimuth angles. This operation works as rotation-based data augmentation.
        # `None`: No virtual rotations are done.
        train_rotation_bias=['virtual_rot', 'azi_random', None][0],

        cgnet_params=dict(
            nb_class=11,
            half_dense_feature=128,
            half_fc_feature=128,
            nb_skip_bin=4,
            # CNN parameters
            nb_layer=5,
            nb_skip_l0_features=[-1, 8, 8, 8, 0],
            Lmax=3,
            taus_cgins=[[2, 2], [16, 4, 2], [48, 8, 4, 2], [64, 12, 8, 4], [64, 16, 8, 8]],
            sphharm_activation_enabled_ls=[[], [], [], [1, 2, 3], [1]],
            pooling_ns=[8, 8, 4, 1, 1],
            cnn_kernel_sizes=[(3, 3), (3, 3), (3, 3), (cnn_half_time_len * 2 + 1, 4), (cnn_half_time_len * 2 + 1, 1)],
            cnn_skip_l0s=[False, False, False, False, True],
            cnn_paddings=[(1, 1), (1, 1), (1, 1), (cnn_half_time_len, 0), (cnn_half_time_len, 0)],
            dropout=0.5,
            use_GRU=True,
            nb_gru_layer=2,
            dropout_gru=0.2,
            sphstdbatchnorm_momentum=0.01,
            sphstdbatchnorm_eps=1e-10,
            sphharmactivation_eps=1e-10,
            scale_equivariance=True,
            cgbilinear_eps=1e-10,
        )
    )
    return params
